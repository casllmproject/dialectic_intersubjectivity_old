{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi3MlMBPwAVhU+2CWOcyE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casllmproject/dialectic_intersubjectivity/blob/main/ICR_WD_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlCMK0IMmJDy"
      },
      "outputs": [],
      "source": [
        "#ICR dataset for fox analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data files\n",
        "df_A = pd.read_csv('{file}.csv') #zeroshot default\n",
        "df_B = pd.read_csv('{file}.csv') #finetune zeroshot\n",
        "df_C = pd.read_csv('{file}.csv') #default dem\n",
        "df_D = pd.read_csv('{file}.csv') #default rep\n",
        "df_E = pd.read_csv('{file}.csv') #ft dem\n",
        "df_F = pd.read_csv('{file}.csv') #ft rep\n",
        "\n",
        "# Vertically combine the two sentiment columns in each file, dropping the original labels\n",
        "df_A_combined = pd.concat([df_A['Biden_Chunk_Responses'].head(100), df_A['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_A')\n",
        "df_B_combined = pd.concat([df_B['Biden_Chunk_Responses'].head(100), df_B['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_B')\n",
        "df_C_combined = pd.concat([df_C['Biden_Chunk_Responses'].head(100), df_C['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_C')\n",
        "df_D_combined = pd.concat([df_D['Biden_Chunk_Responses'].head(100), df_D['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_D')\n",
        "df_E_combined = pd.concat([df_E['Biden_Chunk_Responses'].head(100), df_E['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_E')\n",
        "df_F_combined = pd.concat([df_F['Biden_Chunk_Responses'].head(100), df_F['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_F')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ICR dataset for MSNBC analysis\n",
        "# Load the data files\n",
        "df_A1 = pd.read_csv('{folder_file}.csv') #zeroshot default\n",
        "df_B1 = pd.read_csv('{folder_file}.csv') #finetune zeroshot\n",
        "df_C1 = pd.read_csv('{folder_file}.csv') #default dem\n",
        "df_D1 = pd.read_csv('{folder_file}.csv') #default rep\n",
        "df_E1 = pd.read_csv('{folder_file}.csv') #ft dem\n",
        "df_F1 = pd.read_csv('{folder_file}.csv') #ft rep\n",
        "\n",
        "# Vertically combine the two sentiment columns in each file, dropping the original labels\n",
        "df_A1_combined = pd.concat([df_A1['Biden_Chunk_Responses'].head(100), df_A1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_A')\n",
        "df_B1_combined = pd.concat([df_B1['Biden_Chunk_Responses'].head(100), df_B1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_B')\n",
        "df_C1_combined = pd.concat([df_C1['Biden_Chunk_Responses'].head(100), df_C1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_C')\n",
        "df_D1_combined = pd.concat([df_D1['Biden_Chunk_Responses'].head(100), df_D1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_D')\n",
        "df_E1_combined = pd.concat([df_E1['Biden_Chunk_Responses'].head(100), df_E1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_E')\n",
        "df_F1_combined = pd.concat([df_F1['Biden_Chunk_Responses'].head(100), df_F1['Trump_Chunk_Responses'].head(100)], ignore_index=True).to_frame(name='combined_sentiment_F')"
      ],
      "metadata": {
        "id": "lw4nrKEpn5Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ICR dataset for FOX+MSNBC analysis\n",
        "\n",
        "# Vertically combine the two sentiment columns in each file, dropping the original labels\n",
        "df_AF_combined = pd.concat([df_A_combined['combined_sentiment_A'], df_A1_combined['combined_sentiment_A']], ignore_index=True).to_frame(name='combined_sentiment_AF')\n",
        "df_BF_combined = pd.concat([df_B_combined['combined_sentiment_B'], df_B1_combined['combined_sentiment_B']], ignore_index=True).to_frame(name='combined_sentiment_BF')\n",
        "df_CF_combined = pd.concat([df_C_combined['combined_sentiment_C'], df_C1_combined['combined_sentiment_C']], ignore_index=True).to_frame(name='combined_sentiment_CF')\n",
        "df_DF_combined = pd.concat([df_D_combined['combined_sentiment_D'], df_D1_combined['combined_sentiment_D']], ignore_index=True).to_frame(name='combined_sentiment_DF')\n",
        "df_EF_combined = pd.concat([df_E_combined['combined_sentiment_E'], df_E1_combined['combined_sentiment_E']], ignore_index=True).to_frame(name='combined_sentiment_EF')\n",
        "df_FF_combined = pd.concat([df_F_combined['combined_sentiment_F'], df_F1_combined['combined_sentiment_F']], ignore_index=True).to_frame(name='combined_sentiment_FF')"
      ],
      "metadata": {
        "id": "a6IWDJ02oHDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the two combined dataframes into a new dataframe with two columns\n",
        "df_A_B = pd.concat([df_AF_combined, df_BF_combined], axis=1)\n",
        "df_A_C = pd.concat([df_AF_combined, df_CF_combined], axis=1)\n",
        "df_A_D = pd.concat([df_AF_combined, df_DF_combined], axis=1)\n",
        "df_A_E = pd.concat([df_AF_combined, df_EF_combined], axis=1)\n",
        "df_A_F = pd.concat([df_AF_combined, df_FF_combined], axis=1)\n",
        "df_B_C = pd.concat([df_BF_combined, df_CF_combined], axis=1)\n",
        "df_B_D = pd.concat([df_BF_combined, df_DF_combined], axis=1)\n",
        "df_B_E = pd.concat([df_BF_combined, df_EF_combined], axis=1)\n",
        "df_B_F = pd.concat([df_BF_combined, df_FF_combined], axis=1)\n",
        "df_C_D = pd.concat([df_CF_combined, df_DF_combined], axis=1)\n",
        "df_C_E = pd.concat([df_CF_combined, df_EF_combined], axis=1)\n",
        "df_C_F = pd.concat([df_CF_combined, df_FF_combined], axis=1)\n",
        "df_D_E = pd.concat([df_DF_combined, df_EF_combined], axis=1)\n",
        "df_D_F = pd.concat([df_DF_combined, df_FF_combined], axis=1)\n",
        "df_E_F = pd.concat([df_EF_combined, df_FF_combined], axis=1)\n",
        "\n",
        "# Add 2 to every value in the combined DataFrames (for ordinal scale Krippendorff's Alpha test)\n",
        "df_A_B += 2\n",
        "df_A_C += 2\n",
        "df_A_D += 2\n",
        "df_A_E += 2\n",
        "df_A_F += 2\n",
        "df_B_C += 2\n",
        "df_B_D += 2\n",
        "df_B_E += 2\n",
        "df_B_F += 2\n",
        "df_C_D += 2\n",
        "df_C_E += 2\n",
        "df_C_F += 2\n",
        "df_D_E += 2\n",
        "df_D_F += 2\n",
        "df_E_F += 2\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "df_A_B.to_csv('{folder}/A_B_icr_set.csv', index=False, header=False)\n",
        "df_A_C.to_csv('{folder}/A_C_icr_set.csv', index=False, header=False)\n",
        "df_A_D.to_csv('{folder}/A_D_icr_set.csv', index=False, header=False)\n",
        "df_A_E.to_csv('{folder}/A_E_icr_set.csv', index=False, header=False)\n",
        "df_A_F.to_csv('{folder}/A_F_icr_set.csv', index=False, header=False)\n",
        "df_B_C.to_csv('{folder}/B_C_icr_set.csv', index=False, header=False)\n",
        "df_B_D.to_csv('{folder}/B_D_icr_set.csv', index=False, header=False)\n",
        "df_B_E.to_csv('{folder}/B_E_icr_set.csv', index=False, header=False)\n",
        "df_B_F.to_csv('{folder}/B_F_icr_set.csv', index=False, header=False)\n",
        "df_C_D.to_csv('{folder}/C_D_icr_set.csv', index=False, header=False)\n",
        "df_C_E.to_csv('{folder}/C_E_icr_set.csv', index=False, header=False)\n",
        "df_C_F.to_csv('{folder}/C_F_icr_set.csv', index=False, header=False)\n",
        "df_D_E.to_csv('{folder}/D_E_icr_set.csv', index=False, header=False)\n",
        "df_D_F.to_csv('{folder}/D_F_icr_set.csv', index=False, header=False)\n",
        "df_E_F.to_csv('{folder}/E_F_icr_set.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "RUBJ9YiTm77r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA for Mean differences"
      ],
      "metadata": {
        "id": "jVan88tr1k--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Function to add \"Sentiment_Contrast\" column for a given file\n",
        "def add_sentiment_contrast(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Sentiment_Contrast'] = df['Biden_Sentiment'] - df['Trump_Sentiment']\n",
        "    return df\n",
        "\n",
        "# List of file paths\n",
        "files = [\n",
        "    '{folder}/coded_fox_oct27_averaged_d.csv',\n",
        "    '{folder}/coded_fox_oct27_averaged_ft.csv',\n",
        "    '{folder}/coded_fox_oct27_averaged_demz.csv',\n",
        "    '{folder}/coded_fox_oct27_averaged_repz.csv',\n",
        "    '{folder}/coded_fox_oct27_averaged_demft.csv',\n",
        "    '{folder}/coded_fox_oct27_averaged_repft.csv'\n",
        "]\n",
        "\n",
        "# List to store Sentiment_Contrast columns\n",
        "contrast_data = []\n",
        "\n",
        "for file in files:\n",
        "    df = add_sentiment_contrast(file)\n",
        "    file_label = file.split('/')[-1].split('_')[-1].split('.')[0]  # Extracting the label from the file name\n",
        "    df['File'] = file_label  # Add a column to identify the file\n",
        "    contrast_data.append(df[['Sentiment_Contrast', 'File']])\n",
        "\n",
        "# Combine all contrast data into a long-format DataFrame for ANOVA and Tukey analysis\n",
        "long_format_df = pd.concat(contrast_data)\n",
        "\n",
        "# ANOVA test\n",
        "model = ols('Sentiment_Contrast ~ File', data=long_format_df).fit()\n",
        "anova_results = sm.stats.anova_lm(model, typ=2)\n",
        "print(\"ANOVA Results:\")\n",
        "print(anova_results)\n",
        "\n",
        "# Check if ANOVA result is significant\n",
        "if anova_results['PR(>F)'][0] < 0.05:\n",
        "    # Perform Tukey's HSD post-hoc test\n",
        "    tukey_results = pairwise_tukeyhsd(long_format_df['Sentiment_Contrast'], long_format_df['File'], alpha=0.05)\n",
        "    print(\"\\nTukey's HSD Results:\")\n",
        "    print(tukey_results)\n",
        "\n",
        "    # Display results with p-value significance levels\n",
        "    print(\"\\nPairwise Comparisons with Significance Levels:\")\n",
        "    tukey_df = pd.DataFrame(data=tukey_results.summary().data[1:], columns=tukey_results.summary().data[0])\n",
        "    tukey_df['Mean Difference'] = tukey_df['meandiff'].round(3)  # Round to 3 decimal places for clarity\n",
        "    tukey_df['Significance'] = tukey_df['p-adj'].apply(\n",
        "        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
        "    )\n",
        "    tukey_df = tukey_df[['group1', 'group2', 'Mean Difference', 'p-adj', 'Significance']]\n",
        "    tukey_df.columns = ['Group 1', 'Group 2', 'Mean Difference', 'p-value', 'Significance']  # Renaming columns for readability\n",
        "    print(tukey_df)\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo significant differences found by ANOVA; Tukey's HSD test not performed.\")\n",
        "\n",
        "# Save the combined Sentiment_Contrast data for each file to CSV\n",
        "long_format_df.to_csv('{folder}/Sentiment_Contrast_combined_fox.csv', index=False)\n",
        "print(\"Sentiment Contrast combined data saved to 'Sentiment_Contrast_combined_fox.csv'.\")"
      ],
      "metadata": {
        "id": "a2yWMG1I_VVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A one-way ANOVA was conducted to examine the effect of file type on sentiment contrast. The results showed a statistically significant effect of file type on sentiment contrast, F(5, 1446) = 120.72, p < .001, η² = 0.294, indicating a large effect size."
      ],
      "metadata": {
        "id": "ridgFwYO_wJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add \"Sentiment_Contrast\" column for a given file\n",
        "def add_sentiment_contrast(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Sentiment_Contrast'] = df['Biden_Sentiment'] - df['Trump_Sentiment']\n",
        "    return df\n",
        "\n",
        "# List of file paths\n",
        "files = [\n",
        "    '{folder}/coded_msnbc_oct27_averaged_d.csv',\n",
        "    '{folder}/coded_msnbc_oct27_averaged_ft.csv',\n",
        "    '{folder}/coded_msnbc_oct27_averaged_demz.csv',\n",
        "    '{folder}/coded_msnbc_oct27_averaged_repz.csv',\n",
        "    '{folder}/coded_msnbc_oct27_averaged_demft.csv',\n",
        "    '{folder}/coded_msnbc_oct27_averaged_repft.csv'\n",
        "]\n",
        "\n",
        "# List to store Sentiment_Contrast columns\n",
        "contrast_data = []\n",
        "\n",
        "for file in files:\n",
        "    df = add_sentiment_contrast(file)\n",
        "    file_label = file.split('/')[-1].split('_')[-1].split('.')[0]  # Extracting the label from the file name\n",
        "    df['File'] = file_label  # Add a column to identify the file\n",
        "    contrast_data.append(df[['Sentiment_Contrast', 'File']])\n",
        "\n",
        "# Combine all contrast data into a long-format DataFrame for ANOVA and Tukey analysis\n",
        "long_format_df = pd.concat(contrast_data)\n",
        "\n",
        "# ANOVA test\n",
        "model = ols('Sentiment_Contrast ~ File', data=long_format_df).fit()\n",
        "anova_results = sm.stats.anova_lm(model, typ=2)\n",
        "print(\"ANOVA Results:\")\n",
        "print(anova_results)\n",
        "\n",
        "# Check if ANOVA result is significant\n",
        "if anova_results['PR(>F)'][0] < 0.05:\n",
        "    # Perform Tukey's HSD post-hoc test\n",
        "    tukey_results = pairwise_tukeyhsd(long_format_df['Sentiment_Contrast'], long_format_df['File'], alpha=0.05)\n",
        "    print(\"\\nTukey's HSD Results:\")\n",
        "    print(tukey_results)\n",
        "\n",
        "    # Display results with p-value significance levels\n",
        "    print(\"\\nPairwise Comparisons with Significance Levels:\")\n",
        "    tukey_df = pd.DataFrame(data=tukey_results.summary().data[1:], columns=tukey_results.summary().data[0])\n",
        "    tukey_df['Mean Difference'] = tukey_df['meandiff'].round(3)  # Round to 3 decimal places for clarity\n",
        "    tukey_df['Significance'] = tukey_df['p-adj'].apply(\n",
        "        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
        "    )\n",
        "    tukey_df = tukey_df[['group1', 'group2', 'Mean Difference', 'p-adj', 'Significance']]\n",
        "    tukey_df.columns = ['Group 1', 'Group 2', 'Mean Difference', 'p-value', 'Significance']  # Renaming columns for readability\n",
        "    print(tukey_df)\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo significant differences found by ANOVA; Tukey's HSD test not performed.\")\n",
        "\n",
        "# Save the combined Sentiment_Contrast data for each file to CSV\n",
        "long_format_df.to_csv('{folder}/Sentiment_Contrast_combined_msnbc.csv', index=False)\n",
        "print(\"Sentiment Contrast combined data saved to 'Sentiment_Contrast_combined_msnbc.csv'.\")\n"
      ],
      "metadata": {
        "id": "2dcLcXax1bM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A one-way ANOVA was conducted to evaluate differences in sentiment contrast across six groups (File). The analysis revealed a statistically significant effect of file on sentiment contrast, F(5, 1446) = 70.45, p < .001, η² = 0.197, indicating a moderate effect size.\n",
        "\n"
      ],
      "metadata": {
        "id": "tZNb2OoE-6Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wasserstein_distance\n",
        "\n",
        "# Load datasets A and B and calculate Sentiment_Contrast\n",
        "df_E = pd.read_csv('{folder}/coded_fox_oct27_chunks_demft.csv')\n",
        "df_F = pd.read_csv('{folder}/coded_fox_oct27_chunks_repft.csv')\n",
        "df_E1 = pd.read_csv('{folder}/coded_msnbc_oct27_chunks_demft.csv')\n",
        "df_F1 = pd.read_csv('{folder}/coded_msnbc_oct27_chunks_repft.csv')\n",
        "\n",
        "# Compute Sentiment_Contrast\n",
        "df_E['Sentiment_Contrast'] = df_E['Biden_Chunk_Responses'] - df_E['Trump_Chunk_Responses']\n",
        "df_F['Sentiment_Contrast'] = df_F['Biden_Chunk_Responses'] - df_F['Trump_Chunk_Responses']\n",
        "df_E1['Sentiment_Contrast'] = df_E1['Biden_Chunk_Responses'] - df_E1['Trump_Chunk_Responses']\n",
        "df_F1['Sentiment_Contrast'] = df_F1['Biden_Chunk_Responses'] - df_F1['Trump_Chunk_Responses']\n",
        "\n",
        "# Calculate Wasserstein distance between cross-cutting distributions\n",
        "wasserstein_dist = wasserstein_distance(df_E['Sentiment_Contrast'], df_F1['Sentiment_Contrast'])\n",
        "print(f\"Wasserstein Distance between Democrat and Republican persona distributions: {wasserstein_dist:.2f}\")\n",
        "\n",
        "# Plot the distributions with enhanced styling\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.kdeplot(df_E['Sentiment_Contrast'], fill=True, color='#004c99', label='Democrat persona(for Fox News)', alpha=0.6, linewidth=2)\n",
        "sns.kdeplot(df_F1['Sentiment_Contrast'], fill=True, color='#cc0000', label='Republican persona(for MSNBC)', alpha=0.4, linewidth=2)\n",
        "\n",
        "# Mean lines and annotations\n",
        "plt.axvline(df_E['Sentiment_Contrast'].mean(), color='#003366', linestyle='--', linewidth=1.5, label='Mean Democrat-persona')\n",
        "plt.axvline(df_F1['Sentiment_Contrast'].mean(), color='#990000', linestyle='--', linewidth=1.5, label='Mean Republican-persona')\n",
        "plt.text(df_E['Sentiment_Contrast'].mean(), 0.02, f'Mean: {df_E[\"Sentiment_Contrast\"].mean():.2f}', color='#003366', ha='center', fontsize=9)\n",
        "plt.text(df_F1['Sentiment_Contrast'].mean(), 0.04, f'Mean: {df_F1[\"Sentiment_Contrast\"].mean():.2f}', color='#990000', ha='center', fontsize=9)\n",
        "\n",
        "# Title and labels with enhanced font settings\n",
        "plt.title(\"Sentiment Contrast Distribution in Cross-Cutting Transcript Analysis\", fontsize=16, weight='bold')\n",
        "plt.xlabel(\"Sentiment Contrast\", fontsize=14)\n",
        "plt.ylabel(\"Density\", fontsize=14)\n",
        "\n",
        "# Display Wasserstein distance on the plot\n",
        "plt.figtext(0.70, 0.85, f'Wasserstein Distance: {wasserstein_dist:.2f}', fontsize=12, color='black')\n",
        "\n",
        "# Enhanced legend\n",
        "plt.legend(title=\"Model Persona and Outlet\", title_fontsize='13', fontsize='11', loc='upper left', frameon=True, shadow=True)\n",
        "\n",
        "# Grid and show plot\n",
        "plt.grid(visible=True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UPSTBwJDO9Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Wasserstein distance between cross-cutting distributions\n",
        "wasserstein_dist = wasserstein_distance(df_E1['Sentiment_Contrast'], df_F['Sentiment_Contrast'])\n",
        "print(f\"Wasserstein Distance between Democrat and Republican persona distributions: {wasserstein_dist:.2f}\")\n",
        "\n",
        "# Plot the distributions with enhanced styling\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.kdeplot(df_E1['Sentiment_Contrast'], fill=True, color='#004c99', label='Democrat persona(for MSNBC)', alpha=0.6, linewidth=2)\n",
        "sns.kdeplot(df_F['Sentiment_Contrast'], fill=True, color='#cc0000', label='Republican persona(for FoxNews)', alpha=0.4, linewidth=2)\n",
        "\n",
        "# Mean lines and annotations\n",
        "plt.axvline(df_E1['Sentiment_Contrast'].mean(), color='#003366', linestyle='--', linewidth=1.5, label='Mean Democrat-persona')\n",
        "plt.axvline(df_F['Sentiment_Contrast'].mean(), color='#990000', linestyle='--', linewidth=1.5, label='Mean Republican-persona')\n",
        "plt.text(df_E1['Sentiment_Contrast'].mean(), 0.02, f'Mean: {df_E1[\"Sentiment_Contrast\"].mean():.2f}', color='#003366', ha='center', fontsize=9)\n",
        "plt.text(df_F['Sentiment_Contrast'].mean(), 0.04, f'Mean: {df_F[\"Sentiment_Contrast\"].mean():.2f}', color='#990000', ha='center', fontsize=9)\n",
        "\n",
        "# Title and labels with enhanced font settings\n",
        "plt.title(\"Sentiment Contrast Distribution in like-minded Transcript Analysis\", fontsize=16, weight='bold')\n",
        "plt.xlabel(\"Sentiment Contrast\", fontsize=14)\n",
        "plt.ylabel(\"Density\", fontsize=14)\n",
        "\n",
        "# Display Wasserstein distance on the plot\n",
        "plt.figtext(0.70, 0.85, f'Wasserstein Distance: {wasserstein_dist:.2f}', fontsize=12, color='black')\n",
        "\n",
        "# Enhanced legend\n",
        "plt.legend(title=\"Model Persona and Outlet\", title_fontsize='13', fontsize='11', loc='upper left', frameon=True, shadow=True)\n",
        "\n",
        "# Grid and show plot\n",
        "plt.grid(visible=True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PLJgVdJuRTX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}