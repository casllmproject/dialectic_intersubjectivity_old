{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP22kSMCjxSdB5yF0896c+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casllmproject/dialectic_intersubjectivity/blob/main/FOX_NEWS_ANALYSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from collections import Counter\n",
        "from collections import deque\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import tiktoken # for token counting\n",
        "from collections import defaultdict\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "mbvXJylaHwqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('{folder}/fox_oct27.csv')"
      ],
      "metadata": {
        "id": "oi0znPYnnQOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "DHKI9xA1pWfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "w7ROPoWnpacr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the API key by reading from the file\n",
        "openai.api_key = open(\"{folder}_casllm_apikey.txt\", \"r\").read().strip(\"\\n\")"
      ],
      "metadata": {
        "id": "VGq-ZuseYjbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using default model\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant that codes sentiment toward Joe Biden and Donald Trump.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the default model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o-2024-08-06\",  # Use default model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfdz = pd.read_csv('{folder}/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfdz['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfdz['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfdz['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfdz[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_d.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}_coded_fox_oct27_chunks_d.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_d.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_d.csv'\")"
      ],
      "metadata": {
        "id": "AbPzWyJgI0dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "GH1qkPRIkQuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "xgem0BSmkVgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('{folder}/coded_fox_oct27_averaged_d.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('{folder}/coded_fox_sentiments_only_d.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")\n"
      ],
      "metadata": {
        "id": "IoHNQMJbqvBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using fine-tuned model\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant that codes sentiment toward Joe Biden and Donald Trump.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the fine-tuned model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"ft:gpt-4o-2024-08-06:personal::{ft_model_ID}\",  # Use fine-tuned model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfftz = pd.read_csv('{folder}/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfftz['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfftz['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfftz['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfftz[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_ft.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}/coded_fox_oct27_chunks_ft.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_ft.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_ft.csv'\")\n"
      ],
      "metadata": {
        "id": "ZnRDjh1dgZBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "-Rj4mOwoj8tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "XTeLSS4kj9t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('{folder}/coded_fox_oct27_averaged_ft.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('{folder}/coded_fox_sentiments_only_ft.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")\n"
      ],
      "metadata": {
        "id": "rOFaHfN7mA-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using default model+Dem-persona\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You are simulating the persona of a U.S. citizen who is a woman in her 20s, black, with a college degree, Democrat, and middle income.\n",
        "                You will code the sentiment toward Joe Biden and Donald Trump based on this persona.\n",
        "                \"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the default model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o-2024-08-06\",  # Use fine-tuned model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfdemz = pd.read_csv('{folder}/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfdemz['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfdemz['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfdemz['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfdemz[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_demz.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}/coded_fox_oct27_chunks_demz.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_demz.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_demz.csv'\")"
      ],
      "metadata": {
        "id": "mDIYdqpmx8cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "8eGR7OkfLrb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "04Vsyg3SyJsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('{folder}/coded_fox_oct27_averaged_demz.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('{folder}/coded_fox_sentiments_only_demz.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")"
      ],
      "metadata": {
        "id": "rxcdm9tAL7ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using default model+Rep-persona\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You are simulating the persona of a U.S. citizen who is a man in his 50s, white, with a HS degree, Republican, and upper-middle income.\n",
        "                You will code the sentiment toward Joe Biden and Donald Trump based on this persona.\n",
        "                \"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the default model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o-2024-08-06\",  # Use fine-tuned model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfrepz = pd.read_csv('{folder}/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfrepz['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfrepz['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfrepz['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfrepz[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_repz.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}/coded_fox_oct27_chunks_repz.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_repz.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_repz.csv'\")"
      ],
      "metadata": {
        "id": "qlhMLio4z8St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "eRs-iva8MxcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "__pR86lbM0rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/CASLLM/coded_fox_oct27_averaged_repz.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('/content/drive/MyDrive/CASLLM/coded_fox_sentiments_only_repz.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")"
      ],
      "metadata": {
        "id": "a3ct23QSM4WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using fine-tuned model+Dem-persona\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You are simulating the persona of a U.S. citizen who is a woman in her 20s, black, with a college degree, Democrat, and middle income.\n",
        "                You will code the sentiment toward Joe Biden and Donald Trump based on this persona.\n",
        "                \"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the fine-tuned model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"ft:gpt-4o-2024-08-06:personal::{ft_model_ID}\",  # Use fine-tuned model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfdemft = pd.read_csv('/content/drive/MyDrive/CASLLM/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfdemft['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfdemft['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfdemft['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfdemft[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_demft.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}/coded_fox_oct27_chunks_demft.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_demft.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_demft.csv'\")"
      ],
      "metadata": {
        "id": "jK3CInskNeXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "bZzyoSJYN3cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "16yPFEdCN5bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('{folder}/coded_fox_oct27_averaged_demft.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('{folder}/coded_fox_sentiments_only_demft.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")"
      ],
      "metadata": {
        "id": "iK00CAnPN7XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to code the text with only numeric responses using fine-tuned model+Rep-persona\n",
        "def code_text_ft(text):\n",
        "    # Convert the text to lowercase to handle case sensitivity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split text into smaller chunks (keeping each chunk within the token limit)\n",
        "    chunks = textwrap.wrap(text, width=2000, break_long_words=False)\n",
        "\n",
        "    # Initialize lists to store responses for each chunk\n",
        "    biden_responses = []\n",
        "    trump_responses = []\n",
        "\n",
        "    # Iterate through each chunk\n",
        "    for chunk in chunks:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You are simulating the persona of a U.S. citizen who is a man in his 50s, white, with a HS degree, Republican, and upper-middle income.\n",
        "                You will code the sentiment toward Joe Biden and Donald Trump based on this persona.\n",
        "                \"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                For the following text, please provide only numeric sentiment coding for both Joe Biden and Donald Trump without explanation:\n",
        "\n",
        "                Text: \"{chunk}\"\n",
        "\n",
        "                1. Sentiment toward Joe Biden (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "                2. Sentiment toward Donald Trump (-2 for very negative, -1 for negative, 0 for neutral, 1 for positive, 2 for very positive).\n",
        "\n",
        "                Please respond with just the two numbers, one for Joe Biden and one for Donald Trump, separated by a comma. Example: 1, -1\n",
        "                \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Call the fine-tuned model via the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"ft:gpt-4o-2024-08-06:personal::{ft_model_ID}\",  # Use fine-tuned model\n",
        "                messages=messages,\n",
        "                max_tokens=10,  # Keep the token count low since we expect a short response\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Extract the response content and clean it\n",
        "            result = response['choices'][0]['message']['content'].strip()\n",
        "            print(f\"Response: {result}\")  # Debugging: print the response to verify\n",
        "\n",
        "            # Parse the response: expecting a format like \"1, -1\"\n",
        "            biden_sentiment, trump_sentiment = map(int, result.split(','))\n",
        "\n",
        "            # Append each sentiment value to the respective lists\n",
        "            biden_responses.append(biden_sentiment)\n",
        "            trump_responses.append(trump_sentiment)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle any errors that occur during parsing\n",
        "            print(f\"Error parsing response: {e}\")\n",
        "            continue  # Skip this chunk in case of error\n",
        "\n",
        "    # Return lists of responses for Biden and Trump\n",
        "    return biden_responses, trump_responses\n",
        "\n",
        "# Load the dataset\n",
        "dfrepft = pd.read_csv('{folder}/fox_oct27.csv')\n",
        "\n",
        "# Apply the function to the 'body' column and obtain chunk-based responses\n",
        "responses = dfrepft['body'].apply(code_text_ft)\n",
        "\n",
        "# Separate the responses into Biden and Trump lists\n",
        "biden_chunked = [resp[0] for resp in responses]\n",
        "trump_chunked = [resp[1] for resp in responses]\n",
        "\n",
        "# Calculate average sentiment for each text and create a new DataFrame\n",
        "dfrepft['Biden_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in biden_chunked]\n",
        "dfrepft['Trump_Sentiment'] = [sum(resp) / len(resp) if len(resp) > 0 else 0 for resp in trump_chunked]\n",
        "\n",
        "# Save the averaged sentiments to a CSV file\n",
        "average_sentiments = dfrepft[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "average_sentiments.to_csv('{folder}/coded_fox_oct27_averaged_repft.csv', index=False)\n",
        "\n",
        "# Flatten the lists of chunk responses for adding as columns\n",
        "flat_biden_responses = [item for sublist in biden_chunked for item in sublist]\n",
        "flat_trump_responses = [item for sublist in trump_chunked for item in sublist]\n",
        "\n",
        "# Create a DataFrame for chunk-level responses\n",
        "chunk_responses_df = pd.DataFrame({\n",
        "    'Biden_Chunk_Responses': flat_biden_responses,\n",
        "    'Trump_Chunk_Responses': flat_trump_responses\n",
        "})\n",
        "\n",
        "# Save the chunk responses to a separate CSV file\n",
        "chunk_responses_df.to_csv('{folder}/coded_fox_oct27_chunks_repft.csv', index=False)\n",
        "\n",
        "print(\"Averaged sentiments saved to '{folder}/coded_fox_oct27_averaged_repft.csv'\")\n",
        "print(\"Chunk responses saved to '{folder}/coded_fox_oct27_chunks_repft.csv'\")"
      ],
      "metadata": {
        "id": "eJziiCk8PkWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sentiments"
      ],
      "metadata": {
        "id": "qcsMcUKHQMf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_responses_df"
      ],
      "metadata": {
        "id": "O12QPN6gQN5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original dataset\n",
        "df = pd.read_csv('{folder}/coded_fox_oct27_averaged_repft.csv')\n",
        "\n",
        "# Select only the \"Biden_Sentiment\" and \"Trump_Sentiment\" columns\n",
        "df_selected = df[['Biden_Sentiment', 'Trump_Sentiment']]\n",
        "\n",
        "# Save the new dataset to a CSV file\n",
        "df_selected.to_csv('{folder}/coded_fox_sentiments_only_repft.csv', index=False)\n",
        "\n",
        "# Calculate mean and standard deviation for each column\n",
        "biden_mean = df_selected['Biden_Sentiment'].mean()\n",
        "biden_sd = df_selected['Biden_Sentiment'].std()\n",
        "trump_mean = df_selected['Trump_Sentiment'].mean()\n",
        "trump_sd = df_selected['Trump_Sentiment'].std()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Biden Sentiment - Mean: {biden_mean}, SD: {biden_sd}\")\n",
        "print(f\"Trump Sentiment - Mean: {trump_mean}, SD: {trump_sd}\")"
      ],
      "metadata": {
        "id": "H7vQk-WZQRxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}